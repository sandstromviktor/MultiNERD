{
    "test_ANIM": {
        "f1": 0.5979809046799187,
        "number": 32390,
        "precision": 0.8162589466937293,
        "recall": 0.4718122877431306
    },
    "test_BIO": {
        "f1": 0.33333333333333337,
        "number": 250,
        "precision": 0.5918367346938775,
        "recall": 0.232
    },
    "test_CEL": {
        "f1": 0.848690053285968,
        "number": 33900,
        "precision": 0.8012786919610104,
        "recall": 0.9020648967551622
    },
    "test_DIS": {
        "f1": 0.5632798573975044,
        "number": 30676,
        "precision": 0.8069066147859922,
        "recall": 0.43265093232494456
    },
    "test_EVE": {
        "f1": 0.46299810246679324,
        "number": 1406,
        "precision": 0.6951566951566952,
        "recall": 0.34708392603129445
    },
    "test_FOOD": {
        "f1": 0.9493909168843297,
        "number": 6373068,
        "precision": 0.9484336384930283,
        "recall": 0.9503501296392883
    },
    "test_INST": {
        "f1": 0.8887969849581431,
        "number": 145830,
        "precision": 0.8652207792207792,
        "recall": 0.9136940272920524
    },
    "test_LOC": {
        "f1": 0.471377694470478,
        "number": 28342,
        "precision": 0.5027991042866283,
        "recall": 0.4436525298144097
    },
    "test_MEDIA": {
        "f1": 0.5903777740132136,
        "number": 11838,
        "precision": 0.5919823339561746,
        "recall": 0.5887818888325731
    },
    "test_MYTH": {
        "f1": 0.3809244600801329,
        "number": 11032,
        "precision": 0.413186347254611,
        "recall": 0.3533357505438724
    },
    "test_ORG": {
        "f1": 0.4934200095132392,
        "number": 5994,
        "precision": 0.4700906344410876,
        "recall": 0.5191858525191858
    },
    "test_PER": {
        "f1": 0.9265113266362464,
        "number": 169556,
        "precision": 0.9088763573235905,
        "recall": 0.9448441812734436
    },
    "test_PLANT": {
        "f1": 0.8069180606747943,
        "number": 6484,
        "precision": 0.7465897166841553,
        "recall": 0.8778531770512029
    },
    "test_TIME": {
        "f1": 0.29100357258850273,
        "number": 4106,
        "precision": 0.43664717348927873,
        "recall": 0.21821724305893814
    },
    "test_VEHI": {
        "f1": 0.6929890689785149,
        "number": 11472,
        "precision": 0.7541017227235439,
        "recall": 0.6410390516039052
    },
    "test_loss": 0.07974159717559814,
    "test_overall_accuracy": 0.9300611488260135,
    "test_overall_f1": 0.9396593505958284,
    "test_overall_precision": 0.9399149886122043,
    "test_overall_recall": 0.9394038515984635,
    "test_runtime": 1931.6892,
    "test_samples_per_second": 229.058,
    "test_steps_per_second": 7.159
}